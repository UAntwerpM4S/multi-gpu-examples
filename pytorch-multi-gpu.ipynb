{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88fde604-7538-4154-85d3-b644be5a3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ab28487-1968-456c-9638-6c62359453ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.device('cuda')     # Default CUDA device\n",
    "cuda0 = torch.device('cuda:0')  # GPU 0 (these are 0-indexed)\n",
    "cuda1 = torch.device('cuda:1')  # GPU 1 (these are 0-indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7297186e-7a3a-4033-9195-0b241aa4b4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a cuda:1\n",
      "b cuda:1\n",
      "b2 cuda:1\n",
      "c cuda:1\n",
      "z cuda:0\n",
      "d cuda:0\n",
      "e cuda:0\n",
      "f cuda:0\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1., 2.], device=cuda0)\n",
    "# x.device is device(type='cuda', index=0)\n",
    "y = torch.tensor([1., 2.]).cuda()\n",
    "# y.device is device(type='cuda', index=0)\n",
    "\n",
    "with torch.cuda.device(1):\n",
    "    # allocates a tensor on GPU 1\n",
    "    a = torch.tensor([1., 2.], device=cuda)\n",
    "\n",
    "    # transfers a tensor from CPU to GPU 1\n",
    "    b = torch.tensor([1., 2.]).cuda()\n",
    "    # a.device and b.device are device(type='cuda', index=1)\n",
    "\n",
    "    print('a', a.device)\n",
    "    print('b', b.device)\n",
    "\n",
    "    # You can also use ``Tensor.to`` to transfer a tensor:\n",
    "    b2 = torch.tensor([1., 2.]).to(device=cuda)\n",
    "    # b.device and b2.device are device(type='cuda', index=1)\n",
    "\n",
    "    print('b2', b2.device)\n",
    "\n",
    "    c = a + b\n",
    "    # c.device is device(type='cuda', index=1)\n",
    "\n",
    "    print('c', c.device)\n",
    "\n",
    "    z = x + y\n",
    "    # z.device is device(type='cuda', index=0)\n",
    "\n",
    "    print('z', z.device)\n",
    "    \n",
    "    # even within a context, you can specify the device\n",
    "    # (or give a GPU index to the .cuda call)\n",
    "    d = torch.randn(2, device=cuda0)\n",
    "    e = torch.randn(2).to(cuda0)\n",
    "    f = torch.randn(2).cuda(cuda0)\n",
    "    # d.device, e.device, and f.device are all device(type='cuda', index=2)\n",
    "\n",
    "    print('d', d.device)\n",
    "    print('e', e.device)\n",
    "    print('f', f.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddc197-43b2-4405-8848-6d10b697f1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85edfbe8-98c4-4883-a5e3-850adf8479bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-pytorch",
   "language": "python",
   "name": ".venv-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
